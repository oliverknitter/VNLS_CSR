import torch
import torch.nn as nn
import numpy as np

from .hamiltonian import Hamiltonian
from scipy.sparse import csr_matrix

# Takes A as a compressed sparse row storage (csr_matrix) format from scipy.sparse
# Does not presume A is Hermitian, unlike standard VNLS
# Does presume A is real
class VQLS_direct(Hamiltonian):
    def __init__(self, A, b):
        super(VQLS_direct, self).__init__()
        self.A = A
        self.A_transpose = csr_matrix(csr_matrix.transpose(self.A))
        self.A_squared = self.A_transpose*self.A

        self.b = b
        self.b_dist, self.b_total, self.b_indexes = self.square_b()
        self.n, self.U, self.K = self.alias_method()
    
    def square_b(self): # Returns the unnormalized probability distribution of b, the normalization factor, and indexes for the keys of b
        indexes = {}
        b_dist = {}
        counter = 1
        for key in self.b.keys():
            indexes[counter] = key
            b_dist[key] = self.b[key]**2
            counter += 1 
        return b_dist, sum(b_dist.values()), indexes

    def alias_method(self): # Prepares and returns lookup tables for Alias method sampling: https://en.wikipedia.org/wiki/Alias_method
        n = len(self.b_dist)
        U = np.zeros(n)
        K = np.zeros(n)

        overfull = []
        underfull = []
        exact = []

        for i in range(n):
            U[i] = n*self.b_dist[self.b_indexes[i+1]]/self.b_total
            if U[i] > 1:
                overfull.append(i+1)
            elif U[i] < 1:
                underfull.append(i+1)
            else:
                exact.append(i+1)
        for i in exact:
            K[i-1] = i

        while overfull and underfull:
            over = overfull.pop(0)
            under = underfull.pop(0)
            K[under - 1] = over
            U[over - 1] += U[under - 1] - 1.0
            exact.append(under)
            if U[over - 1] > 1:
                overfull.append(over)
            elif U[over - 1] < 1:
                underfull.append(over)
            else:
                exact.append(over)

        while overfull:
            over = overfull.pop(0)
            U[over - 1] = 1.0

        while underfull:
            under = underfull.pop(0)
            U[under - 1] = 1.0
        
        return n, U, K

    def b_sampler(self, batch_size): # Samples spin configurations from |b|^2 distribution using lookup tables generated by self.alias_method()
        random_samples = np.random.rand(batch_size)
        i = np.floor(self.n*random_samples) + 1
        i = i.astype(int)
        y = self.n*random_samples + 1 - i

        for j in range(batch_size):
            if y[j] >= self.U[i[j]-1]:
                i[j] = self.K[i[j]-1]
        
        sample_configs = []
        for j in i:
            sample_configs.append(self.b_indexes[j])
        return torch.Tensor(sample_configs)

    def b_eval(self, samples): # Returns corresponding values of b for a given batch of spin configurations
        values = []
        for item in samples.numpy():
            key = tuple(item)
            if key in self.b:
                values.append(self.b[key])
            else:
                values.append(0.0)
        return torch.Tensor(values)

    def row_product(self, samples, observable, model=None): # Takes entries from model if one is provided, otherwise takes entries from b.
        batch_size = samples.shape[0]
        num_sites = samples.shape[1]
        values = torch.zeros(batch_size) # Create output vector for batch
        values = torch.complex(values,values)
        samples_copy = (-0.5*(samples.detach().clone().numpy() - 1.0)).astype(int) # Copies samples into binary numpy array

        powers = 2**np.arange(num_sites)[::-1]
        rows = np.matmul(samples_copy, powers) # row sample indexes in decimal

        for sample_index in range(batch_size):
            row_pointers = observable.indptr[rows[sample_index]:rows[sample_index]+2] # CSR pointers for sample row and successive row
            if row_pointers[0] == row_pointers[1]: # Handle case that the row is empty
                continue

            column = observable.indices[row_pointers[0]:row_pointers[1]] # Column indexes of nonzero values in decimal
            row_entries = torch.from_numpy(observable.data[row_pointers[0]:row_pointers[1]]) # Nonzero values of row

            column = column.reshape([-1,1]) # Convert column indexes to binary
            columns_binary = torch.from_numpy(-2.0*((column & powers).astype(bool).astype(float))+1)
            columns_binary = columns_binary.type(torch.float)

            if model is not None:
                vector_entries = model(columns_binary).exp()
                row_entries=row_entries.type(torch.complex64)
            else:
                vector_entries = self.b_eval(columns_binary)
                row_entries = row_entries.type(torch.float)
                
            values[sample_index] += torch.dot(row_entries, vector_entries)

        return values
    
    def b_mean(self, model, batch_size = 128): # Samples a batch of confirguations from |b|^2 and averages the corresponding local energies of A.
        b_samples = self.b_sampler(batch_size)
        b_vals = self.b_eval(b_samples)
        energies = self.row_product(b_samples, self.A, model)/b_vals
        mean = torch.mean(energies)
        return mean

    def compute_local_energy(self, samples, model): # Computes the local energy of the VQLS Hamiltonian.
        with torch.no_grad():
            mean = self.b_mean(model, samples.shape[0]) # Currently set to compute local energy for b_configurations in sample batches of size num_sites.
            local_energy = self.row_product(samples, self.A_squared, model) - self.row_product(samples, self.A_transpose)*mean
        log_psi = model(samples)
        return local_energy/log_psi.exp(), log_psi

    def compute_model_vector(self, num_sites, model):
        with torch.no_grad():
            input = torch.zeros((2**num_sites, num_sites))
            for i in range(2**num_sites):
                input[i] = torch.Tensor(-2.0*(np.fromiter(np.binary_repr(i, width = num_sites), dtype=float))+1)
        
            solution = torch.real(model(input).exp())        
            solution /= torch.linalg.norm(solution)
        return solution.detach()